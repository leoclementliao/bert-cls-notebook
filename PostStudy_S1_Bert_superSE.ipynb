{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "PostStudy_S1_Bert_superSE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leoclementliao/bert-cls-notebook/blob/master/PostStudy_S1_Bert_superSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXrAlQ6EmeEZ",
        "colab_type": "code",
        "outputId": "16b31fb1-2cab-42fb-92d4-04d0c0659edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr 30 11:29:31 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0ZbLarhm7B4",
        "colab_type": "code",
        "outputId": "1c41097f-5183-4260-a75a-c894d5dafa69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzBUkvEf8Rtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "version_name = 'PS_Bert_SSE1'\n",
        "test_name = f'/content/drive/My Drive/Colab Notebooks/kaggle_covid19NLP/submission/{version_name}.csv'\n",
        "lr_global = 1e-6\n",
        "lr_dense = 2e-4\n",
        "batch_size = 64\n",
        "epochs_num = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2KuGVXdnGOA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "680d90dd-2c5f-420b-9b52-907be4062f5a"
      },
      "source": [
        "% cp -r /content/drive/My\\ Drive/Colab\\ Notebooks/kaggle_covid19NLP /content\n",
        "% cd /content/kaggle_covid19NLP/notebook\n",
        "# ! unzip /content/kaggle_covid19NLP/RoBERTa_zh_L12_PyTorch.zip -d /content/kaggle_covid19NLP/RoBERTa_zh_L12_PyTorch\n",
        "# ! unzip /content/kaggle_covid19NLP/data/test_dataset.zip -d /content/kaggle_covid19NLP/data/test_dataset"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/kaggle_covid19NLP/notebook\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LGHV67EjITC",
        "colab_type": "text"
      },
      "source": [
        "# Install transformers library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb4QbS4orR0z",
        "colab_type": "code",
        "outputId": "94a98b85-62c8-4ac6-dc6b-d6948a36affb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 7.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 46.9MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 46.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.46)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.46 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.46)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=32852e2f29d45cfbc862a0d8b7c144cab3ab83a95eefabd4aa55f42d31bc09c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK7e9Ettq2Sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_probability as tfp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM8LIWwJjITE",
        "colab_type": "code",
        "outputId": "e3a0bacc-7291-462a-be61-4fb7e14e3324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "# import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# from tensorflow.keras.layers import (GlobalAveragePooling1D, Reshape, Conv1D,\n",
        "#                                      multiply)\n",
        "import os\n",
        "import time, gc\n",
        "\n",
        "from transformers import *\n",
        "print(tf.__version__)\n",
        "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
        "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "\n",
        "# Enable XLA\n",
        "#tf.config.optimizer.set_jit(True)\n",
        "\n",
        "# Enable AMP\n",
        "#tf.keras.mixed_precision.experimental.set_policy('mixed_float16')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j-ekrehjITK",
        "colab_type": "code",
        "outputId": "8454eae8-add4-4f96-b2f3-82285b1ede2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "TRAIN_PATH = '../data/train_dataset/nCoV_100k_train.labled.csv' \n",
        "\n",
        "TEST_PATH = '../data/test_dataset/nCov_10k_test.csv'\n",
        "SUB_PATH = '../data/submit_example.csv'\n",
        "\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 140\n",
        "input_categories = '微博中文内容'\n",
        "output_categories = '情感倾向'\n",
        "\n",
        "df_train = pd.read_csv(TRAIN_PATH)\n",
        "df_test = pd.read_csv(TEST_PATH)\n",
        "df_train = df_train[df_train[output_categories].isin(['-1','0','1'])]\n",
        "\n",
        "df_sub = pd.read_csv(SUB_PATH)\n",
        "print('train shape =', df_train.shape)\n",
        "print('test shape =', df_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape = (99913, 7)\n",
            "test shape = (10000, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgN6uSdxCvCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_output_arrays(df, columns):\n",
        "    return np.asarray(df[columns].astype(int) + 1)\n",
        "outputs = compute_output_arrays(df_train, output_categories)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR6sHlQTjITO",
        "colab_type": "text"
      },
      "source": [
        "# Convert tokens to feature vectors\n",
        "<img src=\"https://imgkr.cn-bj.ufileos.com/341d1c83-45cf-4e9b-a656-a547cd0f2c67.png\" width=\"50%\" height=\"50%\" />\n",
        "\n",
        "transformer chinese weight\n",
        "- https://github.com/ymcui/Chinese-BERT-wwm\n",
        "- https://github.com/brightmart/roberta_zh\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27cLzFjUjITQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _convert_to_transformer_inputs(instance, tokenizer, max_sequence_length):\n",
        "    \"\"\"Converts tokenized input to ids, masks and segments for transformer (including bert)\"\"\"\n",
        "    \"\"\" return input_ids,token_type_ids,attention_mask\"\"\"\n",
        "    inputs = tokenizer.encode_plus(instance,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_sequence_length,\n",
        "        truncation_strategy= 'longest_first')\n",
        "\n",
        "    input_ids =  inputs[\"input_ids\"]\n",
        "    input_masks = inputs[\"attention_mask\"]\n",
        "    input_segments = inputs[\"token_type_ids\"]\n",
        "    padding_length = max_sequence_length - len(input_ids)\n",
        "    #填充\n",
        "    padding_id = tokenizer.pad_token_id\n",
        "    input_ids = input_ids + ([padding_id] * padding_length)\n",
        "    input_masks = input_masks + ([0] * padding_length)\n",
        "    input_segments = input_segments + ([0] * padding_length)\n",
        "    return [input_ids, input_masks, input_segments]\n",
        "\n",
        "\n",
        "def compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n",
        "    input_ids, input_masks, input_segments = [], [], []\n",
        "    for instance in tqdm(df[columns]):\n",
        "        \n",
        "        ids, masks, segments = _convert_to_transformer_inputs(str(instance), tokenizer, max_sequence_length)\n",
        "        \n",
        "        input_ids.append(ids)\n",
        "        input_masks.append(masks)\n",
        "        input_segments.append(segments)\n",
        "\n",
        "    return [np.asarray(input_ids, dtype=np.int32), \n",
        "            np.asarray(input_masks, dtype=np.int32), \n",
        "            np.asarray(input_segments, dtype=np.int32)\n",
        "           ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ikbnW8cjITU",
        "colab_type": "code",
        "outputId": "0aaa4e71-f247-4743-c9a0-2ecac25f0802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "BERT_PATH = '/content/kaggle_covid19NLP/bert_base_chinese'\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_PATH+'/bert-base-chinese-vocab.txt')\n",
        "\n",
        "inputs = compute_input_arrays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
        "test_inputs = compute_input_arrays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n",
            "100%|██████████| 99913/99913 [01:01<00:00, 1613.58it/s]\n",
            "100%|██████████| 10000/10000 [00:05<00:00, 1675.04it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1ZJ0YakjITZ",
        "colab_type": "code",
        "outputId": "2bb26003-c5e6-4153-dee3-291667028246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "tokenizer.encode_plus(\"武汉加油\",\n",
        "        add_special_tokens=True,\n",
        "        max_length=20,\n",
        "        truncation_strategy= 'longest_first')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': [1, 1, 1, 1, 1, 1],\n",
              " 'input_ids': [101, 3636, 3727, 1217, 3779, 102],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0JJcTz7jITo",
        "colab_type": "text"
      },
      "source": [
        "# BERT model\n",
        "\n",
        "https://huggingface.co/models\n",
        "\n",
        "\n",
        "<img src=\"https://imgkr.cn-bj.ufileos.com/9115ac01-f455-498b-8c38-9c4abb04046c.png\" width=\"50%\" height=\"50%\" />\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii2xwiyxtz5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Not used in this compitition\n",
        "def Focal_Loss(y_true, y_pred, alpha=0.5, gamma=2):\n",
        "    \"\"\"\n",
        "    focal loss for multi-class classification\n",
        "    fl(pt) = -alpha*(1-pt)^(gamma)*log(pt)\n",
        "    :param y_true: ground truth one-hot vector shape of [batch_size, nb_class]\n",
        "    :param y_pred: prediction after softmax shape of [batch_size, nb_class]\n",
        "    :param alpha:\n",
        "    :param gamma:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    y_pred += tf.keras.backend.epsilon()\n",
        "    ce = -y_true * tf.math.log(y_pred)\n",
        "    weight = tf.pow(1 - y_pred, gamma) * y_true\n",
        "    fl = ce * weight * alpha\n",
        "    reduce_fl = tf.keras.backend.max(fl, axis=-1)\n",
        "    return reduce_fl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWVLFKE6jITp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea4WURNRjITu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "checkpoints = []\n",
        "for fold_index in range(5):\n",
        "    model_name = 'emo_fold_%d_bert_f1_{epoch:02d}.h5' % fold_index#{out_dense_1_accuracy:.4f}\n",
        "    if not os.path.isdir(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    filepath = os.path.join(save_dir, model_name)\n",
        "    \n",
        "    checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                                 monitor='val_f1',\n",
        "                                  mode='max',\n",
        "                                 verbose=1,save_weights_only=True,\n",
        "                                 save_best_only=True)\n",
        "    checkpoints.append(checkpoint)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yNyhbwfjITz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer\n",
        "class Initi(tf.keras.initializers.Initializer ):\n",
        "\n",
        "    \"\"\"Initializer that generates tensors initialized to 1.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    def __call__(self, shape, dtype=None):\n",
        "\n",
        "        out = np.zeros( shape=shape, dtype=np.float32)\n",
        "        #out[0] = 1\n",
        "        #out[-1] = -1\n",
        "        #out[-2] = 0\n",
        "        #out[-3] = 0\n",
        "        #out[-4] = 0\n",
        "        return out\n",
        "\n",
        "\n",
        "class Weighted_sum(Layer):\n",
        "\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        self.output_dim = output_dim\n",
        "        super(Weighted_sum, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create a trainable weight variable for this layer.\n",
        "        self.kernel = self.add_weight(name='weighted_sum', \n",
        "                                      shape=(input_shape[-1], self.output_dim),\n",
        "                                      initializer=Initi(),\n",
        "                                      trainable=True)\n",
        "        super(Weighted_sum, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, x):\n",
        "        return K.dot(x, K.softmax(self.kernel,-2))#tf.linalg.matmul\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape#(input_shape[0], self.output_dim)\n",
        "\n",
        "\n",
        "def SE_layer(stacked_layers):\n",
        "    num_filters_out = stacked_layers.shape[2]\n",
        "    se = tf.keras.layers.GlobalAveragePooling1D()(stacked_layers)\n",
        "    se = tf.keras.layers.Reshape((1, num_filters_out))(se)\n",
        "    se = tf.keras.layers.Conv1D(num_filters_out//4, 1,\n",
        "                padding='same',\n",
        "                activation=\"relu\",\n",
        "                kernel_initializer='he_normal',\n",
        "                name='SE_layer1')(se)\n",
        "    se = tf.keras.layers.Conv1D(num_filters_out, 1,\n",
        "                padding='same',\n",
        "                activation='sigmoid',\n",
        "                kernel_initializer='he_normal',\n",
        "                name='SE_layer2')(se)\n",
        "\n",
        "    Layers_SE = tf.keras.layers.multiply([stacked_layers, se])\n",
        "    return Layers_SE\n",
        "\n",
        "\n",
        "def SSE_layer(stacked_layers, F0, F2):\n",
        "    num_filters_out = stacked_layers.shape[2]\n",
        "    stacked_layers = tf.stack([FC2(FC0(layer[:, 0, :])) for layer in stacked_layers],axis = -1)\n",
        "\n",
        "    se = tf.keras.layers.GlobalAveragePooling1D()(stacked_layers)\n",
        "    se = tf.keras.layers.Reshape((1, num_filters_out))(se)\n",
        "    se = tf.keras.layers.Conv1D(num_filters_out//4, 1,\n",
        "                padding='same',\n",
        "                activation=\"relu\",\n",
        "                kernel_initializer='he_normal',\n",
        "                name='SE_layer1')(se)\n",
        "    se = tf.keras.layers.Conv1D(num_filters_out, 1,\n",
        "                padding='same',\n",
        "                activation='sigmoid',\n",
        "                kernel_initializer='he_normal',\n",
        "                name='SE_layer2')(se)\n",
        "\n",
        "    Layers_SE = tf.keras.layers.multiply([stacked_layers, se])\n",
        "    return Layers_SE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTBe874RjIT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from tensorflow.keras.legacy import interfaces\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.python.keras.optimizers import Optimizer\n",
        "\n",
        "class Adam_lr_mult(Optimizer):\n",
        "    \"\"\"Adam optimizer.\n",
        "    Adam optimizer, with learning rate multipliers built on Keras implementation\n",
        "    # Arguments\n",
        "        lr: float >= 0. Learning rate.\n",
        "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
        "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
        "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
        "        decay: float >= 0. Learning rate decay over each update.\n",
        "        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n",
        "            algorithm from the paper \"On the Convergence of Adam and\n",
        "            Beyond\".\n",
        "    # References\n",
        "        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n",
        "        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n",
        "        \n",
        "    AUTHOR: Erik Brorson\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lr=0.001,name = 'mAdam', beta_1=0.9, beta_2=0.999,\n",
        "                 epsilon=None, decay=0., amsgrad=False,\n",
        "                 multipliers=None, debug_verbose=False,**kwargs):\n",
        "        super(Adam_lr_mult, self).__init__(**kwargs)\n",
        "        with K.name_scope(self.__class__.__name__):\n",
        "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
        "            self.lr = K.variable(lr, name='lr')\n",
        "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
        "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
        "            self.decay = K.variable(decay, name='decay')\n",
        "        if epsilon is None:\n",
        "            epsilon = K.epsilon()\n",
        "        self.epsilon = epsilon\n",
        "        self.initial_decay = decay\n",
        "        self.amsgrad = amsgrad\n",
        "        self.multipliers = multipliers\n",
        "        self.debug_verbose = debug_verbose\n",
        "\n",
        "    #@interfaces.legacy_get_updates_support\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
        "                                                  K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
        "                     (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        if self.amsgrad:\n",
        "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        else:\n",
        "            vhats = [K.zeros(1) for _ in params]\n",
        "        self.weights = [self.iterations] + ms + vs + vhats\n",
        "\n",
        "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
        "\n",
        "            # Learning rate multipliers\n",
        "            if self.multipliers:\n",
        "                multiplier = [mult for mult in self.multipliers if mult in p.name]\n",
        "            else:\n",
        "                multiplier = None\n",
        "            if multiplier:\n",
        "                new_lr_t = lr_t * self.multipliers[multiplier[0]]\n",
        "                if self.debug_verbose:\n",
        "                    print('Setting {} to learning rate {}'.format(multiplier[0], new_lr_t))\n",
        "                    print(K.get_value(new_lr_t))\n",
        "            else:\n",
        "                new_lr_t = lr_t\n",
        "                if self.debug_verbose:\n",
        "                    print('No change in learning rate {}'.format(p.name))\n",
        "                    print(K.get_value(new_lr_t))\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            if self.amsgrad:\n",
        "                vhat_t = K.maximum(vhat, v_t)\n",
        "                p_t = p - new_lr_t * m_t / (K.sqrt(vhat_t) + self.epsilon)\n",
        "                self.updates.append(K.update(vhat, vhat_t))\n",
        "            else:\n",
        "                p_t = p - new_lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            new_p = p_t\n",
        "\n",
        "            # Apply constraints.\n",
        "            if getattr(p, 'constraint', None) is not None:\n",
        "                new_p = p.constraint(new_p)\n",
        "\n",
        "            self.updates.append(K.update(p, new_p))\n",
        "        return self.updates\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'lr': float(K.get_value(self.lr)),\n",
        "                  'beta_1': float(K.get_value(self.beta_1)),\n",
        "                  'beta_2': float(K.get_value(self.beta_2)),\n",
        "                  'decay': float(K.get_value(self.decay)),\n",
        "                  'epsilon': self.epsilon,\n",
        "                  'amsgrad': self.amsgrad,\n",
        "                  'multipliers':self.multipliers}\n",
        "        base_config = super(Adam_lr_mult, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVT5CVYNjIT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate_multipliers = {}\n",
        "learning_rate_multipliers['weighted_sum'] = lr_dense/lr_global\n",
        "learning_rate_multipliers['dense0'] = lr_dense/lr_global\n",
        "learning_rate_multipliers['dense1'] = lr_dense/lr_global\n",
        "learning_rate_multipliers['dense2'] = lr_dense/lr_global\n",
        "learning_rate_multipliers['se_reduce'] = lr_dense/lr_global\n",
        "learning_rate_multipliers['se_expand'] = lr_dense/lr_global\n",
        "\n",
        "#learning_rate_multipliers['layer_3'] = 0.1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvX1bgohjIT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Not used in this compitition\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    print(epoch)\n",
        "    lr = 1e-5\n",
        "    \n",
        "    if epoch >0:\n",
        "        lr = 6e-6\n",
        "    #lr = 0.5*(1+np.cos((epoch/epochs)*np.pi))*lr\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBQ3cX8QjIUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "\n",
        "disable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r3RwyiAjIUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  \n",
        "    input_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)    \n",
        "    input_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)    \n",
        "    input_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)    \n",
        "    config = BertConfig.from_pretrained( '../bert_base_chinese/bert-base-chinese-config.json', output_hidden_states=True)\n",
        "    bert_model = TFBertModel.from_pretrained('../bert_base_chinese/bert-base-chinese-tf_model.h5', config=config)\n",
        "    # config = BertConfig.from_pretrained( '../RoBERTa_zh_L12_PyTorch/config.json', output_hidden_states=True)\n",
        "    # bert_model = TFBertModel.from_pretrained('../RoBERTa_zh_L12_PyTorch/pytorch_model.bin',from_pt=True, config=config)\n",
        "    \n",
        "    sequence_output, pooler_output, hidden_states = bert_model(input_id, attention_mask=input_mask, token_type_ids=input_atn)\n",
        "    print(sequence_output.shape)\n",
        "    print(len(hidden_states))\n",
        "\n",
        "    ## Fully connected layers\n",
        "    FC0  = tf.keras.layers.Dense(128, activation='relu',name = \"dense0\")\n",
        "    FC1 = tf.keras.layers.Dense(128, activation='relu',name = \"dense1\")\n",
        "    FC2  = tf.keras.layers.Dense(3, activation='softmax',name = \"dense2\")\n",
        "    \n",
        "    stacked_layers = tf.stack([tf.keras.layers.Dropout(0.1)(layer[:, 0, :]) for layer in hidden_states[1:]],axis = -1)#,noise_shape=(None,None,1)\n",
        "    \n",
        "    ## SSE module\n",
        "    stacked = tf.stack([FC2(FC0(layer[:, 0, :])) for layer in hidden_states[1:]],axis = -1)\n",
        "    se = tf.keras.layers.GlobalMaxPooling1D(name='se_squeeze')(stacked)\n",
        "    se = tf.keras.layers.Reshape((1, 12), name= 'se_reshape')(se)\n",
        "    filters_se = 6\n",
        "    se = tf.keras.layers.Conv1D(filters_se, 1,padding='same',activation=\"relu\",kernel_initializer=\"he_normal\",name='se_reduce')(se)\n",
        "    se = tf.keras.layers.Conv1D(12, 1,padding='same',activation='sigmoid',kernel_initializer=\"he_normal\",name='se_expand')(se)\n",
        "    stacked_layers = tf.keras.layers.multiply([stacked_layers, se], name='se_excite')\n",
        "    cls_output = K.sum(stacked_layers,axis = -1)/tf.cast(12,tf.float32)\n",
        "\n",
        "    #print(shape)\n",
        "    # stacked_layers = SE_layer(stacked_layers)\n",
        "    # cls_output = Weighted_sum(1)(stacked_layers)\n",
        "    # cls_output = K.squeeze(cls_output,axis = -1)\n",
        "    print(cls_output.shape)\n",
        "    #cls_output = tf.keras.layers.GlobalAveragePooling1D()(cls_output)\n",
        "    #x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    #x = tf.keras.layers.Dense(3, activation='softmax',name = \"out\")(x)\n",
        "    # multisample dropout (wut): https://arxiv.org/abs/1905.09788\n",
        "    dense_out = []\n",
        "    \n",
        "    for _ in range(8):\n",
        "        x = tf.keras.layers.Dropout(0.15)(cls_output)\n",
        "        \n",
        "        x = FC0(x)\n",
        "        x = tf.keras.layers.Dropout(0.15)(x)\n",
        "        \n",
        "        #x = FC1(x)\n",
        "        #x = tf.keras.layers.Dropout(0.2)(x)\n",
        "        x = FC2(x)\n",
        "        dense_out.append(x)\n",
        "    \n",
        "    out = tf.keras.layers.average(dense_out)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[input_id, input_mask, input_atn], outputs=out)\n",
        "    #layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
        "    bert_model.bert.pooler.dense.trainable  = False\n",
        "    #optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "    opt = Adam_lr_mult(lr = lr_global, multipliers=learning_rate_multipliers)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc', f1])\n",
        "\n",
        "    # FL=lambda y_true,y_pred: Focal_Loss(y_true, y_pred, alpha=0.25, gamma=2)\n",
        "    # model.compile(loss=FL, optimizer=opt, metrics=['acc', f1])   \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "SvxMzcRKjIUK",
        "colab_type": "code",
        "outputId": "fc02a7c0-334b-41bd-9959-aa483ff366ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = create_model()\n",
        "model.save_weights(\"init_weights.h5\")\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "(None, 140, 768)\n",
            "13\n",
            "(None, 768)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 140)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 140)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 140)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 140, 768), ( 102267648   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_12 (T [(None, 768)]        0           tf_bert_model[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_13 (T [(None, 768)]        0           tf_bert_model[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_14 (T [(None, 768)]        0           tf_bert_model[0][5]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_15 (T [(None, 768)]        0           tf_bert_model[0][6]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_16 (T [(None, 768)]        0           tf_bert_model[0][7]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_17 (T [(None, 768)]        0           tf_bert_model[0][8]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_18 (T [(None, 768)]        0           tf_bert_model[0][9]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_19 (T [(None, 768)]        0           tf_bert_model[0][10]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_20 (T [(None, 768)]        0           tf_bert_model[0][11]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_21 (T [(None, 768)]        0           tf_bert_model[0][12]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_22 (T [(None, 768)]        0           tf_bert_model[0][13]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_23 (T [(None, 768)]        0           tf_bert_model[0][14]             \n",
            "__________________________________________________________________________________________________\n",
            "dense0 (Dense)                  (None, 128)          98432       tf_op_layer_strided_slice_12[0][0\n",
            "                                                                 tf_op_layer_strided_slice_13[0][0\n",
            "                                                                 tf_op_layer_strided_slice_14[0][0\n",
            "                                                                 tf_op_layer_strided_slice_15[0][0\n",
            "                                                                 tf_op_layer_strided_slice_16[0][0\n",
            "                                                                 tf_op_layer_strided_slice_17[0][0\n",
            "                                                                 tf_op_layer_strided_slice_18[0][0\n",
            "                                                                 tf_op_layer_strided_slice_19[0][0\n",
            "                                                                 tf_op_layer_strided_slice_20[0][0\n",
            "                                                                 tf_op_layer_strided_slice_21[0][0\n",
            "                                                                 tf_op_layer_strided_slice_22[0][0\n",
            "                                                                 tf_op_layer_strided_slice_23[0][0\n",
            "                                                                 dropout_49[0][0]                 \n",
            "                                                                 dropout_51[0][0]                 \n",
            "                                                                 dropout_53[0][0]                 \n",
            "                                                                 dropout_55[0][0]                 \n",
            "                                                                 dropout_57[0][0]                 \n",
            "                                                                 dropout_59[0][0]                 \n",
            "                                                                 dropout_61[0][0]                 \n",
            "                                                                 dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 3)            387         dense0[0][0]                     \n",
            "                                                                 dense0[1][0]                     \n",
            "                                                                 dense0[2][0]                     \n",
            "                                                                 dense0[3][0]                     \n",
            "                                                                 dense0[4][0]                     \n",
            "                                                                 dense0[5][0]                     \n",
            "                                                                 dense0[6][0]                     \n",
            "                                                                 dense0[7][0]                     \n",
            "                                                                 dense0[8][0]                     \n",
            "                                                                 dense0[9][0]                     \n",
            "                                                                 dense0[10][0]                    \n",
            "                                                                 dense0[11][0]                    \n",
            "                                                                 dropout_50[0][0]                 \n",
            "                                                                 dropout_52[0][0]                 \n",
            "                                                                 dropout_54[0][0]                 \n",
            "                                                                 dropout_56[0][0]                 \n",
            "                                                                 dropout_58[0][0]                 \n",
            "                                                                 dropout_60[0][0]                 \n",
            "                                                                 dropout_62[0][0]                 \n",
            "                                                                 dropout_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_stack_1 (TensorFlow [(None, 3, 12)]      0           dense2[0][0]                     \n",
            "                                                                 dense2[1][0]                     \n",
            "                                                                 dense2[2][0]                     \n",
            "                                                                 dense2[3][0]                     \n",
            "                                                                 dense2[4][0]                     \n",
            "                                                                 dense2[5][0]                     \n",
            "                                                                 dense2[6][0]                     \n",
            "                                                                 dense2[7][0]                     \n",
            "                                                                 dense2[8][0]                     \n",
            "                                                                 dense2[9][0]                     \n",
            "                                                                 dense2[10][0]                    \n",
            "                                                                 dense2[11][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "se_squeeze (GlobalMaxPooling1D) (None, 12)           0           tf_op_layer_stack_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 768)]        0           tf_bert_model[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [(None, 768)]        0           tf_bert_model[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_2 (Te [(None, 768)]        0           tf_bert_model[0][5]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_3 (Te [(None, 768)]        0           tf_bert_model[0][6]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_4 (Te [(None, 768)]        0           tf_bert_model[0][7]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_5 (Te [(None, 768)]        0           tf_bert_model[0][8]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_6 (Te [(None, 768)]        0           tf_bert_model[0][9]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_7 (Te [(None, 768)]        0           tf_bert_model[0][10]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_8 (Te [(None, 768)]        0           tf_bert_model[0][11]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_9 (Te [(None, 768)]        0           tf_bert_model[0][12]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_10 (T [(None, 768)]        0           tf_bert_model[0][13]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_11 (T [(None, 768)]        0           tf_bert_model[0][14]             \n",
            "__________________________________________________________________________________________________\n",
            "se_reshape (Reshape)            (None, 1, 12)        0           se_squeeze[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_3[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_4[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_5[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_6[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_7[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_8[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_9[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_10[0][0\n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_11[0][0\n",
            "__________________________________________________________________________________________________\n",
            "se_reduce (Conv1D)              (None, 1, 6)         78          se_reshape[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_stack (TensorFlowOp [(None, 768, 12)]    0           dropout_37[0][0]                 \n",
            "                                                                 dropout_38[0][0]                 \n",
            "                                                                 dropout_39[0][0]                 \n",
            "                                                                 dropout_40[0][0]                 \n",
            "                                                                 dropout_41[0][0]                 \n",
            "                                                                 dropout_42[0][0]                 \n",
            "                                                                 dropout_43[0][0]                 \n",
            "                                                                 dropout_44[0][0]                 \n",
            "                                                                 dropout_45[0][0]                 \n",
            "                                                                 dropout_46[0][0]                 \n",
            "                                                                 dropout_47[0][0]                 \n",
            "                                                                 dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "se_expand (Conv1D)              (None, 1, 12)        84          se_reduce[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "se_excite (Multiply)            (None, 768, 12)      0           tf_op_layer_stack[0][0]          \n",
            "                                                                 se_expand[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sum (TensorFlowOpLa [(None, 768)]        0           se_excite[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_truediv (TensorFlow [(None, 768)]        0           tf_op_layer_Sum[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 768)          0           tf_op_layer_truediv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_51 (Dropout)            (None, 768)          0           tf_op_layer_truediv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 768)          0           tf_op_layer_truediv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_55 (Dropout)            (None, 768)          0           tf_op_layer_truediv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_57 (Dropout)            (None, 768)          0           tf_op_layer_truediv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 768)          0           tf_op_layer_truediv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 768)          0           tf_op_layer_truediv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 768)          0           tf_op_layer_truediv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 128)          0           dense0[12][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 128)          0           dense0[13][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 128)          0           dense0[14][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 128)          0           dense0[15][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_58 (Dropout)            (None, 128)          0           dense0[16][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 128)          0           dense0[17][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 128)          0           dense0[18][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 128)          0           dense0[19][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "average (Average)               (None, 3)            0           dense2[12][0]                    \n",
            "                                                                 dense2[13][0]                    \n",
            "                                                                 dense2[14][0]                    \n",
            "                                                                 dense2[15][0]                    \n",
            "                                                                 dense2[16][0]                    \n",
            "                                                                 dense2[17][0]                    \n",
            "                                                                 dense2[18][0]                    \n",
            "                                                                 dense2[19][0]                    \n",
            "==================================================================================================\n",
            "Total params: 102,366,629\n",
            "Trainable params: 101,776,037\n",
            "Non-trainable params: 590,592\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryc8wM72jIUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gkf = StratifiedKFold(n_splits=5).split(X=df_train[input_categories].fillna('-1'), y=df_train[output_categories].fillna('-1'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP8axIHS9nzN",
        "colab_type": "code",
        "outputId": "c5bdc767-9eff-4939-dc2e-bd7e5178c3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "## Not used in this competition.\n",
        "\n",
        "## Tokenizer Back translated data\n",
        "df_train['微博中文内容_En'] = ''\n",
        "\n",
        "TRAIN_aug_PATH = '../data/train_augmentation/translated_data.csv' \n",
        "df_train_aug = pd.read_csv(TRAIN_aug_PATH)\n",
        "df_train['微博中文内容_En'].loc[df_train[input_categories]==df_train[input_categories]] = df_train_aug['微博中文内容_En'].values\n",
        "# df_train.iloc[-5:]\n",
        "inputs_EnTrans = compute_input_arrays(df_train, '微博中文内容_En', tokenizer, MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "def concat_array(A, B, random_order):\n",
        "    AB = np.concatenate((A, B), axis=0)\n",
        "    AB_random = AB[random_order]\n",
        "    return AB_random"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n",
            "100%|██████████| 99913/99913 [01:01<00:00, 1618.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "7C9SoRg3jIUc",
        "colab_type": "code",
        "outputId": "b5604f36-fb6e-4427-a29b-ff828e56e447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# valid_preds = []\n",
        "# test_preds = []\n",
        "# for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
        "#     print(\"fold:\",fold)\n",
        "\n",
        "#     random_order = np.arange(2*len(train_idx))\n",
        "#     ## Take partial data to limite training time\n",
        "#     np.random.shuffle(random_order[len(train_idx):])\n",
        "#     partial_ratio = 0.50 # 0.5 means only use original data\n",
        "#     Num_cut = int(len(random_order)*partial_ratio)\n",
        "#     random_order = random_order[:Num_cut]\n",
        "#     np.random.shuffle(random_order)\n",
        "\n",
        "#     train_inputs = [concat_array(inputs[i][train_idx], inputs_EnTrans[i][train_idx], random_order) for i in range(len(inputs))]\n",
        "#     train_outputs = to_categorical(concat_array(outputs[train_idx], outputs[train_idx], random_order))\n",
        "\n",
        "#     valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n",
        "#     valid_outputs = to_categorical(outputs[valid_idx])\n",
        "\n",
        "#     model.load_weights(\"init_weights.h5\")\n",
        "#     model.fit(train_inputs, train_outputs,validation_data= [valid_inputs, valid_outputs],  epochs=epochs_num, batch_size=batch_size,callbacks = [checkpoints[fold]])#\n",
        "#     model.save_weights(f'bert-{fold}.h5')\n",
        "    # model.save_weights(f'/content/drive/My Drive/Colab Notebooks/kaggle_covid19NLP/model/{version_name}-{fold}.h5')\n",
        "\n",
        "valid_preds = []\n",
        "test_preds = []\n",
        "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
        "    print(\"fold:\",fold)\n",
        "    #if fold!=4:\n",
        "    #    continue\n",
        "    train_inputs = [inputs[i][train_idx] for i in range(len(inputs))]\n",
        "    train_outputs = to_categorical(outputs[train_idx])\n",
        "\n",
        "    valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n",
        "    valid_outputs = to_categorical(outputs[valid_idx])\n",
        "\n",
        "    #K.clear_session()\n",
        "    model.load_weights(\"init_weights.h5\")\n",
        "    #model = create_model()\n",
        "    model.fit(train_inputs, train_outputs,validation_data= [valid_inputs, valid_outputs],  epochs=epochs_num, batch_size=batch_size,callbacks = [checkpoints[fold]])#\n",
        "    model.save_weights(f'bert-{fold}.h5')  "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold: 0\n",
            "Train on 79930 samples, validate on 19983 samples\n",
            "Epoch 1/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.6309 - acc: 0.7232 - f1: 0.7129\n",
            "Epoch 00001: val_f1 improved from -inf to 0.74107, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_0_bert_f1_01.h5\n",
            "79930/79930 [==============================] - 1317s 16ms/sample - loss: 0.6309 - acc: 0.7232 - f1: 0.7129 - val_loss: 0.5694 - val_acc: 0.7464 - val_f1: 0.7411\n",
            "Epoch 2/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.5682 - acc: 0.7527 - f1: 0.7487\n",
            "Epoch 00002: val_f1 improved from 0.74107 to 0.75242, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_0_bert_f1_02.h5\n",
            "79930/79930 [==============================] - 1317s 16ms/sample - loss: 0.5682 - acc: 0.7527 - f1: 0.7487 - val_loss: 0.5527 - val_acc: 0.7572 - val_f1: 0.7524\n",
            "Epoch 3/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.5465 - acc: 0.7625 - f1: 0.7595\n",
            "Epoch 00003: val_f1 did not improve from 0.75242\n",
            "79930/79930 [==============================] - 1319s 17ms/sample - loss: 0.5465 - acc: 0.7625 - f1: 0.7595 - val_loss: 0.5630 - val_acc: 0.7494 - val_f1: 0.7442\n",
            "fold: 1\n",
            "Train on 79930 samples, validate on 19983 samples\n",
            "Epoch 1/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.6382 - acc: 0.7209 - f1: 0.7110\n",
            "Epoch 00001: val_f1 improved from -inf to 0.72551, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_1_bert_f1_01.h5\n",
            "79930/79930 [==============================] - 1320s 17ms/sample - loss: 0.6382 - acc: 0.7209 - f1: 0.7110 - val_loss: 0.5938 - val_acc: 0.7295 - val_f1: 0.7255\n",
            "Epoch 2/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.5673 - acc: 0.7538 - f1: 0.7500\n",
            "Epoch 00002: val_f1 did not improve from 0.72551\n",
            "79930/79930 [==============================] - 1319s 16ms/sample - loss: 0.5673 - acc: 0.7538 - f1: 0.7500 - val_loss: 0.6134 - val_acc: 0.7140 - val_f1: 0.7090\n",
            "Epoch 3/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.5444 - acc: 0.7650 - f1: 0.7617\n",
            "Epoch 00003: val_f1 did not improve from 0.72551\n",
            "79930/79930 [==============================] - 1319s 16ms/sample - loss: 0.5444 - acc: 0.7650 - f1: 0.7617 - val_loss: 0.5925 - val_acc: 0.7273 - val_f1: 0.7244\n",
            "fold: 2\n",
            "Train on 79930 samples, validate on 19983 samples\n",
            "Epoch 1/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.6216 - acc: 0.7272 - f1: 0.7171\n",
            "Epoch 00001: val_f1 improved from -inf to 0.71091, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_2_bert_f1_01.h5\n",
            "79930/79930 [==============================] - 1320s 17ms/sample - loss: 0.6216 - acc: 0.7272 - f1: 0.7171 - val_loss: 0.6556 - val_acc: 0.7151 - val_f1: 0.7109\n",
            "Epoch 2/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.5452 - acc: 0.7627 - f1: 0.7597\n",
            "Epoch 00002: val_f1 did not improve from 0.71091\n",
            "79930/79930 [==============================] - 1319s 17ms/sample - loss: 0.5452 - acc: 0.7627 - f1: 0.7597 - val_loss: 0.6796 - val_acc: 0.7036 - val_f1: 0.6994\n",
            "Epoch 3/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.5208 - acc: 0.7728 - f1: 0.7703\n",
            "Epoch 00003: val_f1 did not improve from 0.71091\n",
            "79930/79930 [==============================] - 1319s 17ms/sample - loss: 0.5208 - acc: 0.7728 - f1: 0.7703 - val_loss: 0.6874 - val_acc: 0.7099 - val_f1: 0.7068\n",
            "fold: 3\n",
            "Train on 79931 samples, validate on 19982 samples\n",
            "Epoch 1/3\n",
            "79931/79931 [==============================] - ETA: 0s - loss: 0.6382 - acc: 0.7190 - f1: 0.7087\n",
            "Epoch 00001: val_f1 improved from -inf to 0.74977, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_3_bert_f1_01.h5\n",
            "79931/79931 [==============================] - 1320s 17ms/sample - loss: 0.6382 - acc: 0.7190 - f1: 0.7087 - val_loss: 0.5851 - val_acc: 0.7515 - val_f1: 0.7498\n",
            "Epoch 2/3\n",
            "79931/79931 [==============================] - ETA: 0s - loss: 0.5667 - acc: 0.7518 - f1: 0.7482\n",
            "Epoch 00002: val_f1 did not improve from 0.74977\n",
            "79931/79931 [==============================] - 1321s 17ms/sample - loss: 0.5667 - acc: 0.7518 - f1: 0.7482 - val_loss: 0.5888 - val_acc: 0.7486 - val_f1: 0.7479\n",
            "Epoch 3/3\n",
            "79931/79931 [==============================] - ETA: 0s - loss: 0.5424 - acc: 0.7638 - f1: 0.7604\n",
            "Epoch 00003: val_f1 did not improve from 0.74977\n",
            "79931/79931 [==============================] - 1320s 17ms/sample - loss: 0.5424 - acc: 0.7638 - f1: 0.7604 - val_loss: 0.5759 - val_acc: 0.7515 - val_f1: 0.7495\n",
            "fold: 4\n",
            "Train on 79931 samples, validate on 19982 samples\n",
            "Epoch 1/3\n",
            "79931/79931 [==============================] - ETA: 0s - loss: 0.6300 - acc: 0.7235 - f1: 0.7112\n",
            "Epoch 00001: val_f1 improved from -inf to 0.72679, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_4_bert_f1_01.h5\n",
            "79931/79931 [==============================] - 1320s 17ms/sample - loss: 0.6300 - acc: 0.7235 - f1: 0.7112 - val_loss: 0.6101 - val_acc: 0.7309 - val_f1: 0.7268\n",
            "Epoch 2/3\n",
            "79931/79931 [==============================] - ETA: 0s - loss: 0.5586 - acc: 0.7555 - f1: 0.7516\n",
            "Epoch 00002: val_f1 improved from 0.72679 to 0.73524, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_4_bert_f1_02.h5\n",
            "79931/79931 [==============================] - 1320s 17ms/sample - loss: 0.5586 - acc: 0.7555 - f1: 0.7516 - val_loss: 0.6010 - val_acc: 0.7397 - val_f1: 0.7352\n",
            "Epoch 3/3\n",
            "79931/79931 [==============================] - ETA: 0s - loss: 0.5333 - acc: 0.7680 - f1: 0.7647\n",
            "Epoch 00003: val_f1 did not improve from 0.73524\n",
            "79931/79931 [==============================] - 1320s 17ms/sample - loss: 0.5333 - acc: 0.7680 - f1: 0.7647 - val_loss: 0.6125 - val_acc: 0.7373 - val_f1: 0.7346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rtPQSB3jIUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVgGXqCHjIUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "\n",
        "    exp_x = np.exp(x)\n",
        "    softmax_x = exp_x / np.sum(exp_x)\n",
        "    return softmax_x "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZm-q0FajIU3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "f55de275-3dda-4d5b-848f-368a4b28b787"
      },
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('saved_models/'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saved_models/emo_fold_1_bert_f1_01.h5\n",
            "saved_models/emo_fold_3_bert_f1_01.h5\n",
            "saved_models/emo_fold_0_bert_f1_01.h5\n",
            "saved_models/emo_fold_4_bert_f1_01.h5\n",
            "saved_models/emo_fold_0_bert_f1_02.h5\n",
            "saved_models/emo_fold_2_bert_f1_01.h5\n",
            "saved_models/emo_fold_4_bert_f1_02.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOCNV6YBjIU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = []\n",
        "def cal_5fold_prediction():\n",
        "    #model = create_model()\n",
        "    model.load_weights(\"bert-0.h5\")\n",
        "    test_preds.append(model.predict(test_inputs,batch_size = 32))\n",
        "    model.load_weights(\"bert-1.h5\")\n",
        "    test_preds.append(model.predict(test_inputs,batch_size = 32))\n",
        "    model.load_weights(\"bert-2.h5\")\n",
        "    test_preds.append(model.predict(test_inputs,batch_size = 32))\n",
        "    model.load_weights(\"bert-3.h5\")\n",
        "    test_preds.append(model.predict(test_inputs,batch_size = 32))\n",
        "    model.load_weights(\"bert-4.h5\")\n",
        "    test_preds.append(model.predict(test_inputs,batch_size = 32))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4guHVvNVjIU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "899982b2-2336-4301-d2ec-4bd79f5429f4"
      },
      "source": [
        "cal_5fold_prediction()# 6min\n",
        "print(len(test_preds))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt4vnONcjIVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_pred = np.average(test_preds, axis=0)\n",
        "sub = np.argmax(avg_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh_SN5x1uPM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pred = df_test[['微博id']].copy()\n",
        "df_pred['-1'] = avg_pred[:, 0]\n",
        "df_pred['0'] = avg_pred[:, 1]\n",
        "df_pred['1'] = avg_pred[:, 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOtjeLCquPJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pred.to_csv(test_name,index=False, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHrC168PuwY9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "67a07b7e-e7b9-454b-e245-0d7b7b9172c5"
      },
      "source": [
        "df_pred"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>微博id</th>\n",
              "      <th>-1</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4456068992182160</td>\n",
              "      <td>0.043455</td>\n",
              "      <td>0.407701</td>\n",
              "      <td>0.548844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4456424178427250</td>\n",
              "      <td>0.554014</td>\n",
              "      <td>0.385873</td>\n",
              "      <td>0.060113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4456797466940200</td>\n",
              "      <td>0.563305</td>\n",
              "      <td>0.406205</td>\n",
              "      <td>0.030491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4456791021108920</td>\n",
              "      <td>0.879372</td>\n",
              "      <td>0.115369</td>\n",
              "      <td>0.005260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4457086404997440</td>\n",
              "      <td>0.785122</td>\n",
              "      <td>0.198265</td>\n",
              "      <td>0.016613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>4464179518243680</td>\n",
              "      <td>0.075560</td>\n",
              "      <td>0.914540</td>\n",
              "      <td>0.009900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>4464274073923100</td>\n",
              "      <td>0.145024</td>\n",
              "      <td>0.696117</td>\n",
              "      <td>0.158859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>4464289160945130</td>\n",
              "      <td>0.030158</td>\n",
              "      <td>0.949725</td>\n",
              "      <td>0.020117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>4465347950314820</td>\n",
              "      <td>0.427457</td>\n",
              "      <td>0.561258</td>\n",
              "      <td>0.011285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>4465492650005690</td>\n",
              "      <td>0.023683</td>\n",
              "      <td>0.754807</td>\n",
              "      <td>0.221510</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  微博id        -1         0         1\n",
              "0     4456068992182160  0.043455  0.407701  0.548844\n",
              "1     4456424178427250  0.554014  0.385873  0.060113\n",
              "2     4456797466940200  0.563305  0.406205  0.030491\n",
              "3     4456791021108920  0.879372  0.115369  0.005260\n",
              "4     4457086404997440  0.785122  0.198265  0.016613\n",
              "...                ...       ...       ...       ...\n",
              "9995  4464179518243680  0.075560  0.914540  0.009900\n",
              "9996  4464274073923100  0.145024  0.696117  0.158859\n",
              "9997  4464289160945130  0.030158  0.949725  0.020117\n",
              "9998  4465347950314820  0.427457  0.561258  0.011285\n",
              "9999  4465492650005690  0.023683  0.754807  0.221510\n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejys0IH0uwgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_QNgC9AjIVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sub = df_test[['微博id']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtRIiPC8jIVe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "94df36dc-12aa-49e7-b3be-3227a491831b"
      },
      "source": [
        "df_sub['y'] = sub-1"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOLM7zWjjIVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sub.columns=['id','y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZKyCcDfjIVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_sub.to_csv(test_name,index=False, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yQe6wtCjIVv",
        "colab_type": "text"
      },
      "source": [
        "# Bert layers name\n",
        "\n",
        "[<tf.Variable 'tf_bert_model/bert/embeddings/word_embeddings/weight:0' shape=(21128, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
        "<tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>,"
      ]
    }
  ]
}