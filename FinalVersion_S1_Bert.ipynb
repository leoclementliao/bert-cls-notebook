{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "FinalVersion_S1_Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leoclementliao/bert-cls-notebook/blob/master/FinalVersion_S1_Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXrAlQ6EmeEZ",
        "colab_type": "code",
        "outputId": "9ff0d026-db64-4956-bdf8-7182e5e7df68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 25 10:31:33 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0ZbLarhm7B4",
        "colab_type": "code",
        "outputId": "254a59e4-537b-406d-d596-ff9db6cbbded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzBUkvEf8Rtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "version_name = 'FV_Bert'\n",
        "test_name = f'/content/drive/My Drive/Colab Notebooks/kaggle_covid19NLP/submission/test_sub{version_name}.csv'\n",
        "lr_global = 1e-6\n",
        "lr_dense = 2e-4\n",
        "batch_size = 80\n",
        "epochs_num = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2KuGVXdnGOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% cp -r /content/drive/My\\ Drive/Colab\\ Notebooks/kaggle_covid19NLP /content\n",
        "% cd /content/kaggle_covid19NLP/notebook\n",
        "# ! unzip /content/kaggle_covid19NLP/RoBERTa_zh_L12_PyTorch.zip -d /content/kaggle_covid19NLP/RoBERTa_zh_L12_PyTorch\n",
        "# ! unzip /content/kaggle_covid19NLP/data/test_dataset.zip -d /content/kaggle_covid19NLP/data/test_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LGHV67EjITC",
        "colab_type": "text"
      },
      "source": [
        "# Install transformers library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb4QbS4orR0z",
        "colab_type": "code",
        "outputId": "e9a1d121-084f-49ad-e6ee-63cdf833790a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK7e9Ettq2Sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_probability as tfp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM8LIWwJjITE",
        "colab_type": "code",
        "outputId": "28915c4e-7226-431f-d14e-3ed891403d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "# import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# from tensorflow.keras.layers import (GlobalAveragePooling1D, Reshape, Conv1D,\n",
        "#                                      multiply)\n",
        "import os\n",
        "import time, gc\n",
        "\n",
        "from transformers import *\n",
        "print(tf.__version__)\n",
        "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
        "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "\n",
        "# Enable XLA\n",
        "#tf.config.optimizer.set_jit(True)\n",
        "\n",
        "# Enable AMP\n",
        "#tf.keras.mixed_precision.experimental.set_policy('mixed_float16')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j-ekrehjITK",
        "colab_type": "code",
        "outputId": "a0e87825-c6ce-4514-be7b-200ce084925d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "TRAIN_PATH = '../data/train_dataset/nCoV_100k_train.labled.csv' \n",
        "\n",
        "TEST_PATH = '../data/test_dataset/nCov_10k_test.csv'\n",
        "SUB_PATH = '../data/submit_example.csv'\n",
        "\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 140\n",
        "input_categories = '微博中文内容'\n",
        "output_categories = '情感倾向'\n",
        "\n",
        "df_train = pd.read_csv(TRAIN_PATH)\n",
        "df_test = pd.read_csv(TEST_PATH)\n",
        "df_train = df_train[df_train[output_categories].isin(['-1','0','1'])]\n",
        "\n",
        "df_sub = pd.read_csv(SUB_PATH)\n",
        "print('train shape =', df_train.shape)\n",
        "print('test shape =', df_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape = (99913, 7)\n",
            "test shape = (10000, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgN6uSdxCvCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_output_arrays(df, columns):\n",
        "    return np.asarray(df[columns].astype(int) + 1)\n",
        "outputs = compute_output_arrays(df_train, output_categories)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR6sHlQTjITO",
        "colab_type": "text"
      },
      "source": [
        "# Convert tokens to feature vectors\n",
        "<img src=\"https://imgkr.cn-bj.ufileos.com/341d1c83-45cf-4e9b-a656-a547cd0f2c67.png\" width=\"50%\" height=\"50%\" />\n",
        "\n",
        "transformer chinese weight\n",
        "- https://github.com/ymcui/Chinese-BERT-wwm\n",
        "- https://github.com/brightmart/roberta_zh\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27cLzFjUjITQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _convert_to_transformer_inputs(instance, tokenizer, max_sequence_length):\n",
        "    \"\"\"Converts tokenized input to ids, masks and segments for transformer (including bert)\"\"\"\n",
        "    \"\"\" return input_ids,token_type_ids,attention_mask\"\"\"\n",
        "    inputs = tokenizer.encode_plus(instance,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_sequence_length,\n",
        "        truncation_strategy= 'longest_first')\n",
        "\n",
        "    input_ids =  inputs[\"input_ids\"]\n",
        "    input_masks = inputs[\"attention_mask\"]\n",
        "    input_segments = inputs[\"token_type_ids\"]\n",
        "    padding_length = max_sequence_length - len(input_ids)\n",
        "    #填充\n",
        "    padding_id = tokenizer.pad_token_id\n",
        "    input_ids = input_ids + ([padding_id] * padding_length)\n",
        "    input_masks = input_masks + ([0] * padding_length)\n",
        "    input_segments = input_segments + ([0] * padding_length)\n",
        "    return [input_ids, input_masks, input_segments]\n",
        "\n",
        "\n",
        "def compute_input_arrays(df, columns, tokenizer, max_sequence_length):\n",
        "    input_ids, input_masks, input_segments = [], [], []\n",
        "    for instance in tqdm(df[columns]):\n",
        "        \n",
        "        ids, masks, segments = _convert_to_transformer_inputs(str(instance), tokenizer, max_sequence_length)\n",
        "        \n",
        "        input_ids.append(ids)\n",
        "        input_masks.append(masks)\n",
        "        input_segments.append(segments)\n",
        "\n",
        "    return [np.asarray(input_ids, dtype=np.int32), \n",
        "            np.asarray(input_masks, dtype=np.int32), \n",
        "            np.asarray(input_segments, dtype=np.int32)\n",
        "           ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ikbnW8cjITU",
        "colab_type": "code",
        "outputId": "dd6e7510-b7c0-4465-99c7-5f17a1643e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "BERT_PATH = '/content/kaggle_covid19NLP/bert_base_chinese'\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_PATH+'/bert-base-chinese-vocab.txt')\n",
        "\n",
        "inputs = compute_input_arrays(df_train, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)\n",
        "test_inputs = compute_input_arrays(df_test, input_categories, tokenizer, MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n",
            "100%|██████████| 99913/99913 [01:11<00:00, 1399.30it/s]\n",
            "100%|██████████| 10000/10000 [00:06<00:00, 1436.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1ZJ0YakjITZ",
        "colab_type": "code",
        "outputId": "47e8bf1a-3845-432b-99b0-ea8c1bddd443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "tokenizer.encode_plus(\"武汉加油\",\n",
        "        add_special_tokens=True,\n",
        "        max_length=20,\n",
        "        truncation_strategy= 'longest_first')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': [1, 1, 1, 1, 1, 1],\n",
              " 'input_ids': [101, 3918, 2428, 722, 4706, 102],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0JJcTz7jITo",
        "colab_type": "text"
      },
      "source": [
        "# BERT model\n",
        "\n",
        "https://huggingface.co/models\n",
        "\n",
        "\n",
        "<img src=\"https://imgkr.cn-bj.ufileos.com/9115ac01-f455-498b-8c38-9c4abb04046c.png\" width=\"50%\" height=\"50%\" />\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii2xwiyxtz5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Not used in this compitition\n",
        "def Focal_Loss(y_true, y_pred, alpha=0.5, gamma=2):\n",
        "    \"\"\"\n",
        "    focal loss for multi-class classification\n",
        "    fl(pt) = -alpha*(1-pt)^(gamma)*log(pt)\n",
        "    :param y_true: ground truth one-hot vector shape of [batch_size, nb_class]\n",
        "    :param y_pred: prediction after softmax shape of [batch_size, nb_class]\n",
        "    :param alpha:\n",
        "    :param gamma:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    y_pred += tf.keras.backend.epsilon()\n",
        "    ce = -y_true * tf.math.log(y_pred)\n",
        "    weight = tf.pow(1 - y_pred, gamma) * y_true\n",
        "    fl = ce * weight * alpha\n",
        "    reduce_fl = tf.keras.backend.max(fl, axis=-1)\n",
        "    return reduce_fl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWVLFKE6jITp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea4WURNRjITu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "checkpoints = []\n",
        "for fold_index in range(5):\n",
        "    model_name = 'emo_fold_%d_bert_f1_{epoch:02d}.h5' % fold_index#{out_dense_1_accuracy:.4f}\n",
        "    if not os.path.isdir(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    filepath = os.path.join(save_dir, model_name)\n",
        "    \n",
        "    checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                                 monitor='val_f1',\n",
        "                                  mode='max',\n",
        "                                 verbose=1,save_weights_only=True,\n",
        "                                 save_best_only=True)\n",
        "    checkpoints.append(checkpoint)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yNyhbwfjITz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer\n",
        "class Initi(tf.keras.initializers.Initializer ):\n",
        "\n",
        "    \"\"\"Initializer that generates tensors initialized to 1.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    def __call__(self, shape, dtype=None):\n",
        "\n",
        "        out = np.zeros( shape=shape, dtype=np.float32)\n",
        "        #out[0] = 1\n",
        "        #out[-1] = -1\n",
        "        #out[-2] = 0\n",
        "        #out[-3] = 0\n",
        "        #out[-4] = 0\n",
        "        return out\n",
        "\n",
        "\n",
        "class Weighted_sum(Layer):\n",
        "\n",
        "    def __init__(self, output_dim, **kwargs):\n",
        "        self.output_dim = output_dim\n",
        "        super(Weighted_sum, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create a trainable weight variable for this layer.\n",
        "        self.kernel = self.add_weight(name='weighted_sum', \n",
        "                                      shape=(input_shape[-1], self.output_dim),\n",
        "                                      initializer=Initi(),\n",
        "                                      trainable=True)\n",
        "        super(Weighted_sum, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, x):\n",
        "        return K.dot(x, K.softmax(self.kernel,-2))#tf.linalg.matmul\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape#(input_shape[0], self.output_dim)\n",
        "\n",
        "\n",
        "def SE_layer(stacked_layers):\n",
        "    num_filters_out = stacked_layers.shape[2]\n",
        "    se = tf.keras.layers.GlobalAveragePooling1D()(stacked_layers)\n",
        "    se = tf.keras.layers.Reshape((1, num_filters_out))(se)\n",
        "    se = tf.keras.layers.Conv1D(num_filters_out//4, 1,\n",
        "                padding='same',\n",
        "                activation=\"relu\",\n",
        "                kernel_initializer='he_normal',\n",
        "                name='SE_layer1')(se)\n",
        "    se = tf.keras.layers.Conv1D(num_filters_out, 1,\n",
        "                padding='same',\n",
        "                activation='sigmoid',\n",
        "                kernel_initializer='he_normal',\n",
        "                name='SE_layer2')(se)\n",
        "\n",
        "    Layers_SE = tf.keras.layers.multiply([stacked_layers, se])\n",
        "    return Layers_SE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTBe874RjIT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from tensorflow.keras.legacy import interfaces\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.python.keras.optimizers import Optimizer\n",
        "\n",
        "class Adam_lr_mult(Optimizer):\n",
        "    \"\"\"Adam optimizer.\n",
        "    Adam optimizer, with learning rate multipliers built on Keras implementation\n",
        "    # Arguments\n",
        "        lr: float >= 0. Learning rate.\n",
        "        beta_1: float, 0 < beta < 1. Generally close to 1.\n",
        "        beta_2: float, 0 < beta < 1. Generally close to 1.\n",
        "        epsilon: float >= 0. Fuzz factor. If `None`, defaults to `K.epsilon()`.\n",
        "        decay: float >= 0. Learning rate decay over each update.\n",
        "        amsgrad: boolean. Whether to apply the AMSGrad variant of this\n",
        "            algorithm from the paper \"On the Convergence of Adam and\n",
        "            Beyond\".\n",
        "    # References\n",
        "        - [Adam - A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980v8)\n",
        "        - [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)\n",
        "        \n",
        "    AUTHOR: Erik Brorson\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lr=0.001,name = 'mAdam', beta_1=0.9, beta_2=0.999,\n",
        "                 epsilon=None, decay=0., amsgrad=False,\n",
        "                 multipliers=None, debug_verbose=False,**kwargs):\n",
        "        super(Adam_lr_mult, self).__init__(**kwargs)\n",
        "        with K.name_scope(self.__class__.__name__):\n",
        "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
        "            self.lr = K.variable(lr, name='lr')\n",
        "            self.beta_1 = K.variable(beta_1, name='beta_1')\n",
        "            self.beta_2 = K.variable(beta_2, name='beta_2')\n",
        "            self.decay = K.variable(decay, name='decay')\n",
        "        if epsilon is None:\n",
        "            epsilon = K.epsilon()\n",
        "        self.epsilon = epsilon\n",
        "        self.initial_decay = decay\n",
        "        self.amsgrad = amsgrad\n",
        "        self.multipliers = multipliers\n",
        "        self.debug_verbose = debug_verbose\n",
        "\n",
        "    #@interfaces.legacy_get_updates_support\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
        "                                                  K.dtype(self.decay))))\n",
        "\n",
        "        t = K.cast(self.iterations, K.floatx()) + 1\n",
        "        lr_t = lr * (K.sqrt(1. - K.pow(self.beta_2, t)) /\n",
        "                     (1. - K.pow(self.beta_1, t)))\n",
        "\n",
        "        ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        if self.amsgrad:\n",
        "            vhats = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n",
        "        else:\n",
        "            vhats = [K.zeros(1) for _ in params]\n",
        "        self.weights = [self.iterations] + ms + vs + vhats\n",
        "\n",
        "        for p, g, m, v, vhat in zip(params, grads, ms, vs, vhats):\n",
        "\n",
        "            # Learning rate multipliers\n",
        "            if self.multipliers:\n",
        "                multiplier = [mult for mult in self.multipliers if mult in p.name]\n",
        "            else:\n",
        "                multiplier = None\n",
        "            if multiplier:\n",
        "                new_lr_t = lr_t * self.multipliers[multiplier[0]]\n",
        "                if self.debug_verbose:\n",
        "                    print('Setting {} to learning rate {}'.format(multiplier[0], new_lr_t))\n",
        "                    print(K.get_value(new_lr_t))\n",
        "            else:\n",
        "                new_lr_t = lr_t\n",
        "                if self.debug_verbose:\n",
        "                    print('No change in learning rate {}'.format(p.name))\n",
        "                    print(K.get_value(new_lr_t))\n",
        "            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n",
        "            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n",
        "            if self.amsgrad:\n",
        "                vhat_t = K.maximum(vhat, v_t)\n",
        "                p_t = p - new_lr_t * m_t / (K.sqrt(vhat_t) + self.epsilon)\n",
        "                self.updates.append(K.update(vhat, vhat_t))\n",
        "            else:\n",
        "                p_t = p - new_lr_t * m_t / (K.sqrt(v_t) + self.epsilon)\n",
        "\n",
        "            self.updates.append(K.update(m, m_t))\n",
        "            self.updates.append(K.update(v, v_t))\n",
        "            new_p = p_t\n",
        "\n",
        "            # Apply constraints.\n",
        "            if getattr(p, 'constraint', None) is not None:\n",
        "                new_p = p.constraint(new_p)\n",
        "\n",
        "            self.updates.append(K.update(p, new_p))\n",
        "        return self.updates\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'lr': float(K.get_value(self.lr)),\n",
        "                  'beta_1': float(K.get_value(self.beta_1)),\n",
        "                  'beta_2': float(K.get_value(self.beta_2)),\n",
        "                  'decay': float(K.get_value(self.decay)),\n",
        "                  'epsilon': self.epsilon,\n",
        "                  'amsgrad': self.amsgrad,\n",
        "                  'multipliers':self.multipliers}\n",
        "        base_config = super(Adam_lr_mult, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVT5CVYNjIT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate_multipliers = {}\n",
        "learning_rate_multipliers['weighted_sum'] = lr_dense/lr_global\n",
        "learning_rate_multipliers['dense0'] = lr_dense/lr_global\n",
        "learning_rate_multipliers['dense1'] = lr_dense/lr_global\n",
        "learning_rate_multipliers['dense2'] = lr_dense/lr_global\n",
        "#learning_rate_multipliers['layer_3'] = 0.1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvX1bgohjIT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Not used in this compitition\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    print(epoch)\n",
        "    lr = 1e-5\n",
        "    \n",
        "    if epoch >0:\n",
        "        lr = 6e-6\n",
        "    #lr = 0.5*(1+np.cos((epoch/epochs)*np.pi))*lr\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBQ3cX8QjIUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "\n",
        "disable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r3RwyiAjIUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    input_id = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)    \n",
        "    input_mask = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)    \n",
        "    input_atn = tf.keras.layers.Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32)    \n",
        "    config = BertConfig.from_pretrained( '../bert_base_chinese/bert-base-chinese-config.json', output_hidden_states=True)\n",
        "    bert_model = TFBertModel.from_pretrained('../bert_base_chinese/bert-base-chinese-tf_model.h5', config=config)\n",
        "    # config = BertConfig.from_pretrained( '../RoBERTa_zh_L12_PyTorch/config.json', output_hidden_states=True)\n",
        "    # bert_model = TFBertModel.from_pretrained('../RoBERTa_zh_L12_PyTorch/pytorch_model.bin',from_pt=True, config=config)\n",
        "    \n",
        "    sequence_output, pooler_output, hidden_states = bert_model(input_id, attention_mask=input_mask, token_type_ids=input_atn)\n",
        "    print(sequence_output.shape)\n",
        "    print(len(hidden_states))\n",
        "    #print(hidden_states[-1].shape)\n",
        "    #(bs,140,768)(bs,768)\n",
        "    \n",
        "    stacked_layers = tf.stack([tf.keras.layers.Dropout(0.1)(layer[:, 0, :]) for layer in hidden_states[1:]],axis = -1)#,noise_shape=(None,None,1)\n",
        "    \n",
        "    #print(shape)\n",
        "    # stacked_layers = SE_layer(stacked_layers)\n",
        "    cls_output = Weighted_sum(1)(stacked_layers)\n",
        "    cls_output = K.squeeze(cls_output,axis = -1)\n",
        "    print(cls_output.shape)\n",
        "    #cls_output = tf.keras.layers.GlobalAveragePooling1D()(cls_output)\n",
        "    #x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    #x = tf.keras.layers.Dense(3, activation='softmax',name = \"out\")(x)\n",
        "    # multisample dropout (wut): https://arxiv.org/abs/1905.09788\n",
        "    dense_out = []\n",
        "    FC0  = tf.keras.layers.Dense(128, activation='relu',name = \"dense0\")\n",
        "    FC1 = tf.keras.layers.Dense(128, activation='relu',name = \"dense1\")\n",
        "    FC2  = tf.keras.layers.Dense(3, activation='softmax',name = \"dense2\")\n",
        "    for _ in range(8):\n",
        "        x = tf.keras.layers.Dropout(0.15)(cls_output)\n",
        "        \n",
        "        x = FC0(x)\n",
        "        x = tf.keras.layers.Dropout(0.15)(x)\n",
        "        \n",
        "        #x = FC1(x)\n",
        "        #x = tf.keras.layers.Dropout(0.2)(x)\n",
        "        x = FC2(x)\n",
        "        dense_out.append(x)\n",
        "    \n",
        "    out = tf.keras.layers.average(dense_out)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[input_id, input_mask, input_atn], outputs=out)\n",
        "    #layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
        "    bert_model.bert.pooler.dense.trainable  = False\n",
        "    #optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "    opt = Adam_lr_mult(lr = lr_global, multipliers=learning_rate_multipliers)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc', f1])\n",
        "\n",
        "    # FL=lambda y_true,y_pred: Focal_Loss(y_true, y_pred, alpha=0.25, gamma=2)\n",
        "    # model.compile(loss=FL, optimizer=opt, metrics=['acc', f1])   \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "SvxMzcRKjIUK",
        "colab_type": "code",
        "outputId": "dc549003-261f-40d0-8214-ace29013421e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = create_model()\n",
        "model.save_weights(\"init_weights.h5\")\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "(None, 140, 768)\n",
            "13\n",
            "(None, 768)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 140)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 140)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 140)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     ((None, 140, 768), ( 102267648   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 768)]        0           tf_bert_model[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [(None, 768)]        0           tf_bert_model[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_2 (Te [(None, 768)]        0           tf_bert_model[0][5]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_3 (Te [(None, 768)]        0           tf_bert_model[0][6]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_4 (Te [(None, 768)]        0           tf_bert_model[0][7]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_5 (Te [(None, 768)]        0           tf_bert_model[0][8]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_6 (Te [(None, 768)]        0           tf_bert_model[0][9]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_7 (Te [(None, 768)]        0           tf_bert_model[0][10]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_8 (Te [(None, 768)]        0           tf_bert_model[0][11]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_9 (Te [(None, 768)]        0           tf_bert_model[0][12]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_10 (T [(None, 768)]        0           tf_bert_model[0][13]             \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_11 (T [(None, 768)]        0           tf_bert_model[0][14]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_3[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_4[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_5[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_6[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_7[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_8[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_9[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_10[0][0\n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 768)          0           tf_op_layer_strided_slice_11[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_stack (TensorFlowOp [(None, 768, 12)]    0           dropout_37[0][0]                 \n",
            "                                                                 dropout_38[0][0]                 \n",
            "                                                                 dropout_39[0][0]                 \n",
            "                                                                 dropout_40[0][0]                 \n",
            "                                                                 dropout_41[0][0]                 \n",
            "                                                                 dropout_42[0][0]                 \n",
            "                                                                 dropout_43[0][0]                 \n",
            "                                                                 dropout_44[0][0]                 \n",
            "                                                                 dropout_45[0][0]                 \n",
            "                                                                 dropout_46[0][0]                 \n",
            "                                                                 dropout_47[0][0]                 \n",
            "                                                                 dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "weighted_sum (Weighted_sum)     (None, 768, 1)       12          tf_op_layer_stack[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze (TensorFlow [(None, 768)]        0           weighted_sum[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 768)          0           tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_51 (Dropout)            (None, 768)          0           tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 768)          0           tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_55 (Dropout)            (None, 768)          0           tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_57 (Dropout)            (None, 768)          0           tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_59 (Dropout)            (None, 768)          0           tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 768)          0           tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 768)          0           tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense0 (Dense)                  (None, 128)          98432       dropout_49[0][0]                 \n",
            "                                                                 dropout_51[0][0]                 \n",
            "                                                                 dropout_53[0][0]                 \n",
            "                                                                 dropout_55[0][0]                 \n",
            "                                                                 dropout_57[0][0]                 \n",
            "                                                                 dropout_59[0][0]                 \n",
            "                                                                 dropout_61[0][0]                 \n",
            "                                                                 dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 128)          0           dense0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 128)          0           dense0[1][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 128)          0           dense0[2][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 128)          0           dense0[3][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_58 (Dropout)            (None, 128)          0           dense0[4][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_60 (Dropout)            (None, 128)          0           dense0[5][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 128)          0           dense0[6][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_64 (Dropout)            (None, 128)          0           dense0[7][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 3)            387         dropout_50[0][0]                 \n",
            "                                                                 dropout_52[0][0]                 \n",
            "                                                                 dropout_54[0][0]                 \n",
            "                                                                 dropout_56[0][0]                 \n",
            "                                                                 dropout_58[0][0]                 \n",
            "                                                                 dropout_60[0][0]                 \n",
            "                                                                 dropout_62[0][0]                 \n",
            "                                                                 dropout_64[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average (Average)               (None, 3)            0           dense2[0][0]                     \n",
            "                                                                 dense2[1][0]                     \n",
            "                                                                 dense2[2][0]                     \n",
            "                                                                 dense2[3][0]                     \n",
            "                                                                 dense2[4][0]                     \n",
            "                                                                 dense2[5][0]                     \n",
            "                                                                 dense2[6][0]                     \n",
            "                                                                 dense2[7][0]                     \n",
            "==================================================================================================\n",
            "Total params: 102,366,479\n",
            "Trainable params: 101,775,887\n",
            "Non-trainable params: 590,592\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryc8wM72jIUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gkf = StratifiedKFold(n_splits=5).split(X=df_train[input_categories].fillna('-1'), y=df_train[output_categories].fillna('-1'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP8axIHS9nzN",
        "colab_type": "code",
        "outputId": "6b8a927f-7b96-40ff-8002-f744981d0d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "## Not used in this competition.\n",
        "\n",
        "## Tokenizer Back translated data\n",
        "df_train['微博中文内容_En'] = ''\n",
        "\n",
        "TRAIN_aug_PATH = '../data/train_augmentation/translated_data.csv' \n",
        "df_train_aug = pd.read_csv(TRAIN_aug_PATH)\n",
        "df_train['微博中文内容_En'].loc[df_train[input_categories]==df_train[input_categories]] = df_train_aug['微博中文内容_En'].values\n",
        "# df_train.iloc[-5:]\n",
        "inputs_EnTrans = compute_input_arrays(df_train, '微博中文内容_En', tokenizer, MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "def concat_array(A, B, random_order):\n",
        "    AB = np.concatenate((A, B), axis=0)\n",
        "    AB_random = AB[random_order]\n",
        "    return AB_random"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n",
            "100%|██████████| 99913/99913 [01:12<00:00, 1383.56it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "7C9SoRg3jIUc",
        "colab_type": "code",
        "outputId": "e6d35cf8-1ef3-4c7d-ba6e-f5fac849d829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "valid_preds = []\n",
        "test_preds = []\n",
        "for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
        "    print(\"fold:\",fold)\n",
        "\n",
        "    random_order = np.arange(2*len(train_idx))\n",
        "    ## Take partial data to limite training time\n",
        "    np.random.shuffle(random_order[len(train_idx):])\n",
        "    partial_ratio = 0.50 # 0.5 means only use original data\n",
        "    Num_cut = int(len(random_order)*partial_ratio)\n",
        "    random_order = random_order[:Num_cut]\n",
        "    np.random.shuffle(random_order)\n",
        "\n",
        "    train_inputs = [concat_array(inputs[i][train_idx], inputs_EnTrans[i][train_idx], random_order) for i in range(len(inputs))]\n",
        "    train_outputs = to_categorical(concat_array(outputs[train_idx], outputs[train_idx], random_order))\n",
        "\n",
        "    valid_inputs = [inputs[i][valid_idx] for i in range(len(inputs))]\n",
        "    valid_outputs = to_categorical(outputs[valid_idx])\n",
        "\n",
        "    model.load_weights(\"init_weights.h5\")\n",
        "    model.fit(train_inputs, train_outputs,validation_data= [valid_inputs, valid_outputs],  epochs=epochs_num, batch_size=batch_size,callbacks = [checkpoints[fold]])#\n",
        "    model.save_weights(f'bert-{fold}.h5')\n",
        "    # model.save_weights(f'/content/drive/My Drive/Colab Notebooks/kaggle_covid19NLP/model/{version_name}-{fold}.h5')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold: 0\n",
            "Train on 79930 samples, validate on 19983 samples\n",
            "Epoch 1/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.6351 - acc: 0.7212 - f1: 0.7115\n",
            "Epoch 00001: val_f1 improved from -inf to 0.74631, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_0_bert_f1_01.h5\n",
            "79930/79930 [==============================] - 1316s 16ms/sample - loss: 0.6351 - acc: 0.7212 - f1: 0.7115 - val_loss: 0.5708 - val_acc: 0.7505 - val_f1: 0.7463\n",
            "Epoch 2/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.5733 - acc: 0.7499 - f1: 0.7454\n",
            "Epoch 00002: val_f1 improved from 0.74631 to 0.75350, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_0_bert_f1_02.h5\n",
            "79930/79930 [==============================] - 1317s 16ms/sample - loss: 0.5733 - acc: 0.7499 - f1: 0.7454 - val_loss: 0.5561 - val_acc: 0.7565 - val_f1: 0.7535\n",
            "Epoch 3/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.5521 - acc: 0.7606 - f1: 0.7573\n",
            "Epoch 00003: val_f1 did not improve from 0.75350\n",
            "79930/79930 [==============================] - 1315s 16ms/sample - loss: 0.5521 - acc: 0.7606 - f1: 0.7573 - val_loss: 0.5867 - val_acc: 0.7403 - val_f1: 0.7373\n",
            "fold: 1\n",
            "Train on 79930 samples, validate on 19983 samples\n",
            "Epoch 1/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.6325 - acc: 0.7241 - f1: 0.7140\n",
            "Epoch 00001: val_f1 improved from -inf to 0.72524, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_1_bert_f1_01.h5\n",
            "79930/79930 [==============================] - 1312s 16ms/sample - loss: 0.6325 - acc: 0.7241 - f1: 0.7140 - val_loss: 0.5950 - val_acc: 0.7319 - val_f1: 0.7252\n",
            "Epoch 2/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.5696 - acc: 0.7522 - f1: 0.7480\n",
            "Epoch 00002: val_f1 did not improve from 0.72524\n",
            "79930/79930 [==============================] - 1313s 16ms/sample - loss: 0.5696 - acc: 0.7522 - f1: 0.7480 - val_loss: 0.5922 - val_acc: 0.7267 - val_f1: 0.7220\n",
            "Epoch 3/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.5459 - acc: 0.7626 - f1: 0.7594\n",
            "Epoch 00003: val_f1 did not improve from 0.72524\n",
            "79930/79930 [==============================] - 1313s 16ms/sample - loss: 0.5459 - acc: 0.7626 - f1: 0.7594 - val_loss: 0.5971 - val_acc: 0.7242 - val_f1: 0.7185\n",
            "fold: 2\n",
            "Train on 79930 samples, validate on 19983 samples\n",
            "Epoch 1/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.6174 - acc: 0.7306 - f1: 0.7219\n",
            "Epoch 00001: val_f1 improved from -inf to 0.71363, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_2_bert_f1_01.h5\n",
            "79930/79930 [==============================] - 1316s 16ms/sample - loss: 0.6174 - acc: 0.7306 - f1: 0.7219 - val_loss: 0.6655 - val_acc: 0.7149 - val_f1: 0.7136\n",
            "Epoch 2/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.5486 - acc: 0.7613 - f1: 0.7583\n",
            "Epoch 00002: val_f1 did not improve from 0.71363\n",
            "79930/79930 [==============================] - 1315s 16ms/sample - loss: 0.5486 - acc: 0.7613 - f1: 0.7583 - val_loss: 0.6911 - val_acc: 0.6958 - val_f1: 0.6913\n",
            "Epoch 3/3\n",
            "79930/79930 [==============================] - ETA: 0s - loss: 0.5254 - acc: 0.7716 - f1: 0.7688\n",
            "Epoch 00003: val_f1 did not improve from 0.71363\n",
            "79930/79930 [==============================] - 1315s 16ms/sample - loss: 0.5254 - acc: 0.7716 - f1: 0.7688 - val_loss: 0.6813 - val_acc: 0.7088 - val_f1: 0.7067\n",
            "fold: 3\n",
            "Train on 79931 samples, validate on 19982 samples\n",
            "Epoch 1/3\n",
            "79931/79931 [==============================] - ETA: 0s - loss: 0.6313 - acc: 0.7231 - f1: 0.7137\n",
            "Epoch 00001: val_f1 improved from -inf to 0.74238, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_3_bert_f1_01.h5\n",
            "79931/79931 [==============================] - 1316s 16ms/sample - loss: 0.6313 - acc: 0.7231 - f1: 0.7137 - val_loss: 0.5984 - val_acc: 0.7444 - val_f1: 0.7424\n",
            "Epoch 2/3\n",
            "79931/79931 [==============================] - ETA: 0s - loss: 0.5688 - acc: 0.7514 - f1: 0.7478\n",
            "Epoch 00002: val_f1 improved from 0.74238 to 0.74765, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_3_bert_f1_02.h5\n",
            "79931/79931 [==============================] - 1315s 16ms/sample - loss: 0.5688 - acc: 0.7514 - f1: 0.7478 - val_loss: 0.5851 - val_acc: 0.7480 - val_f1: 0.7476\n",
            "Epoch 3/3\n",
            "79931/79931 [==============================] - ETA: 0s - loss: 0.5453 - acc: 0.7622 - f1: 0.7591\n",
            "Epoch 00003: val_f1 did not improve from 0.74765\n",
            "79931/79931 [==============================] - 1314s 16ms/sample - loss: 0.5453 - acc: 0.7622 - f1: 0.7591 - val_loss: 0.5817 - val_acc: 0.7498 - val_f1: 0.7475\n",
            "fold: 4\n",
            "Train on 79931 samples, validate on 19982 samples\n",
            "Epoch 1/3\n",
            "79931/79931 [==============================] - ETA: 0s - loss: 0.6275 - acc: 0.7247 - f1: 0.7157\n",
            "Epoch 00001: val_f1 improved from -inf to 0.73368, saving model to /content/kaggle_covid19NLP/notebook/saved_models/emo_fold_4_bert_f1_01.h5\n",
            "79931/79931 [==============================] - 1315s 16ms/sample - loss: 0.6275 - acc: 0.7247 - f1: 0.7157 - val_loss: 0.6117 - val_acc: 0.7372 - val_f1: 0.7337\n",
            "Epoch 2/3\n",
            "35040/79931 [============>.................] - ETA: 11:20 - loss: 0.5626 - acc: 0.7576 - f1: 0.7545"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rtPQSB3jIUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBS4-hMajIUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVgGXqCHjIUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "\n",
        "    exp_x = np.exp(x)\n",
        "    softmax_x = exp_x / np.sum(exp_x)\n",
        "    return softmax_x "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZm-q0FajIU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('saved_models/'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOCNV6YBjIU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = []\n",
        "def cal_5fold_prediction():\n",
        "    #model = create_model()\n",
        "    model.load_weights(\"bert-0.h5\")\n",
        "    test_preds.append(model.predict(test_inputs,batch_size = 32))\n",
        "    model.load_weights(\"bert-1.h5\")\n",
        "    test_preds.append(model.predict(test_inputs,batch_size = 32))\n",
        "    model.load_weights(\"bert-2.h5\")\n",
        "    test_preds.append(model.predict(test_inputs,batch_size = 32))\n",
        "    model.load_weights(\"bert-3.h5\")\n",
        "    test_preds.append(model.predict(test_inputs,batch_size = 32))\n",
        "    model.load_weights(\"bert-4.h5\")\n",
        "    test_preds.append(model.predict(test_inputs,batch_size = 32))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4guHVvNVjIU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cal_5fold_prediction()# 6min\n",
        "print(len(test_preds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt4vnONcjIVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = np.average(test_preds, axis=0)\n",
        "sub = np.argmax(sub,axis=1)\n",
        "# df_sub['y'] = sub-1\n",
        "# #df_sub['id'] = df_sub['id'].apply(lambda x: str(x))\n",
        "# df_sub.to_csv('test_sub.csv',index=False, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aprylvvjIVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds_array = np.array(test_preds)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UExWLGssjIVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToD34w-OjIVQ",
        "colab_type": "text"
      },
      "source": [
        "sub_tmp = np.average(test_preds, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSiEFExLjIVS",
        "colab_type": "text"
      },
      "source": [
        "TMP = sub_tmp[24]\n",
        "\n",
        "TMP = sub_tmp*[1.1,0.9,1]\n",
        "print( TMP[24])\n",
        "\n",
        "sub_tmp = np.argmax(TMP,axis=1)\n",
        "\n",
        "df_sub['y'] = sub_tmp-1\n",
        "\n",
        "df_sub.columns=['id','y']\n",
        "\n",
        "df_sub.head(27)\n",
        "\n",
        "df_sub[\"y\"].value_counts()\n",
        "df_sub.to_csv('test_sub_fix2.csv',index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le1gBzeQjIVT",
        "colab_type": "text"
      },
      "source": [
        "df_sub[\"y\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_QNgC9AjIVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sub = df_test[['微博id']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52vhboEWjIVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sub.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtRIiPC8jIVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sub['y'] = sub-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOLM7zWjjIVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sub.columns=['id','y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4vC8RbFjIVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sub.head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx-TSimojIVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sub[\"y\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZKyCcDfjIVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_sub.to_csv(test_name,index=False, encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yQe6wtCjIVv",
        "colab_type": "text"
      },
      "source": [
        "# Bert layers name\n",
        "\n",
        "[<tf.Variable 'tf_bert_model/bert/embeddings/word_embeddings/weight:0' shape=(21128, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/embeddings/position_embeddings/embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/embeddings/token_type_embeddings/embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>,\n",
        "<tf.Variable 'tf_bert_model/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'tf_bert_model/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'tf_bert_model/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>,"
      ]
    }
  ]
}